{
  "hash": "00239f2c62c1d12e42f6d7cf9d0178ec",
  "result": {
    "markdown": "# Analysis File Creation {#sec-fcreate}\n\n\n```{mermaid}\nflowchart LR\nIm[Import] --> vn[Manageable<br>Variable<br>Names] --> An[Annotate<br>Add Metadata]\nAn --> Int[\"Internal<br>(imported labels)\"] & Ext[External]\nAn --> lu[Labels<br>Units]\nAn --> V[\"View Data Dictionary<br>(metadata)\"]\nIm --> csv[CSV] & bin[Binary]\nIm --> mf[Multiple Files<br>Looping]\n```\n\n\n## Note on File Directory Structure\n\nI have a directory for each major project, and put everything in that\ndirectory (including data files) except for graphics files for\nfigures, which are placed in their own subdirectory underneath the\nproject folder.[With `Quarto` I specify that `html` files are to be self-contained, so there are no separate graphics files.]{.aside}  The directory name for the project includes key\nidentifying information, and files within that directory do not\ncontain project information in their names, nor do they contain dates,\nunless I want to freeze an old version of an analysis script.\n\nFor multi-analyst projects or ones in which you want to capture the entire code history, having the project on `github` is worthwhile.\n\n## Importing and Creating Annotated Analysis Files {#sec-fcreate-import}\n\nI typically create a compact analysis file in a separate R script\ncalled `create.r` and have it produce compressed R binary `data.frame`\nor `data.table` `.rds` files using `saveRDS(name, 'name.rds', compress='xz')`.  Then I have an analysis script named for example `a.qmd` (for [Quarto](https://quarto.org) reports) or `a.Rmd` (for RMarkdown reports) that starts with `d <- readRDS('name.rds')`.  [Templates for analysis reports are [here](http://hbiostat.org/rr/index.html#template), and a comprehensive report example may be found [here](https://hbiostat.org/R/Hmisc/markov).]{.aside} This process is especially helpful with analysis file creation takes multiple steps or files are large.  `readRDS` is very fast for loading binary R objects.  [There is an older way to read/write binary R objects using R `load` and `save` and `Hmisc` frontends for them `Load` and `Save`.  Files using these formats typically have suffixes of `.rda`, `.RData`, or `.sav`, and using `load` stores the object under its original name, which might not be clear until you check your R `.global` environment by looking in the upper right `RStudio` panel.]{.aside}\n\nWhen variables need to be recoded, have labels added or changed, or\nhave units of \nmeasurement added[Variable labels and units of measurement are used in special ways in my R packages.  This will show up in the `describe` and `contents` function outputs below and in axis labels for graphics.]{.aside}, I specify those using the `Hmisc` package [`upData`\nfunction](https://www.rdocumentation.org/packages/Hmisc/versions/4.7-0/topics/upData).\n\nTo facilitate some operations requiring variable names to be quoted, define a function `.q` to quote them automatically. `.q` is like the `Hmisc` function `Cs` but also allows elements to be named.  It will be in `Hmisc` 4.7-1.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n.q <- function(...) {\n  s <- sys.call()[-1]\n  w <- as.character(s)\n  n <- names(s)\n  if(length(n)) names(w) <- n\n  w\n}\n\n.q(a, b, c, 'this and that')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"a\"             \"b\"             \"c\"             \"this and that\"\n```\n:::\n\n```{.r .cell-code}\n.q(dog=a, giraffe=b, cat=c)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    dog giraffe     cat \n    \"a\"     \"b\"     \"c\" \n```\n:::\n:::\n\n\nHere is an `upData` example:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Function to recode from atypical coding for yes/no in raw data\nyn <- function(x) factor(x, 0:1, c('yes', 'no'))\nd <-\n  upData(d,\n         rename = .q(gender=sex, any.event=anyEvent),\n         posSE    = yn(posSE),\n         newMI    = yn(newMI),\n         newPTCA  = yn(newPTCA),\n         newCABG  = yn(newCABG),\n         death    = yn(death),\n         hxofHT   = yn(hxofHT),\n         hxofDM   = yn(hxofDM),\n         hxofCig  = factor(hxofCig, c(0, 0.5, 1),\n                           c('heavy', 'moderate', 'non-smoker')), \n         hxofMI   = yn(hxofMI),\n         hxofPTCA = yn(hxofPTCA),\n         hxofCABG = yn(hxofCABG),\n         chestpain= yn(chestpain),\n         anyEvent = yn(anyEvent),\n         drop=.q(event.no, phat, mics, deltaEF,\n                 newpkmphr, gdpkmphr, gdmaxmphr, gddpeakdp, gdmaxdp,\n                 hardness),\n         labels=c(\n           bhr       = 'Basal heart rate',\n           basebp    = 'Basal blood pressure',\n           basedp    = 'Basal Double Product bhr*basebp',\n           age       = 'Age',\n           pkhr      = 'Peak heart rate',\n           sbp       = 'Systolic blood pressure',\n           dp        = 'Double product pkhr*sbp',\n           dose      = 'Dose of dobutamine given',\n           maxhr     = 'Maximum heart rate',\n           pctMphr   = 'Percent maximum predicted heart rate achieved',\n           mbp       = 'Maximum blood pressure',\n           dpmaxdo   = 'Double product on max dobutamine dose',\n           dobdose   = 'Dobutamine dose at max double product',\n           baseEF    = 'Baseline cardiac ejection fraction',\n           dobEF     = 'Ejection fraction on dobutamine', \n           chestpain = 'Chest pain', \n           ecg       = 'Baseline electrocardiogram diagnosis',\n           restwma   = 'Resting wall motion abnormality on echocardiogram', \n           posSE     = 'Positive stress echocardiogram',\n           newMI     = 'New myocardial infarction',\n           newPTCA   = 'Recent angioplasty',\n           newCABG   = 'Recent bypass surgery', \n           hxofHT    = 'History of hypertension', \n           hxofDM    = 'History of diabetes',\n           hxofMI    = 'History of myocardial infarction',\n           hxofCig   = 'History of smoking',\n           hxofPTCA  = 'History of angioplasty',\n           hxofCABG  = 'History of coronary artery bypass surgery',\n           anyEvent  = 'Death, newMI, newPTCA, or newCABG'),\n         units=.q(age=years, bhr=bpm, basebp=mmHg, basedp='bpm*mmHg',\n           pkhr=mmHg, sbp=mmHg, dp='bpm*mmHg', maxhr=bpm,\n           mbp=mmHg, dpmaxdo='bpm*mmHg', baseEF='%', dobEF='%',\n           pctMphr='%', dose=mg, dobdose=mg)\n         )\n\nsaveRDS(d, 'stressEcho.rds', compress='xz')\n\n# Note that we could have automatically recoded all 0:1 variables\n# if they were all to be treated identically:\n\nfor(x in names(d)) \n  if(all(d[[x]] %in% c(0,1))) d[[x]] <- yn(d[[x]])\n```\n:::\n\n\n::: {.panel-tabset}\n\n##  \n\n\n\n## External Metadata\n\nSometimes metadata comes from a separate source.  Suppose you imported a data frame `d` but have also imported a data frame `m` containing metadata: the same variable names in `d` (variable `name`) plus fields `label`, `units`, and `comment`.  Dataset `m` can contain variables not currently being used.  To add the labels and units into `d` and to store comments separately, use the following example.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- names(d)\ni <- n %nin% m$name\nif(any(i)) cat('The following variables have no metadata:',\n               paste(n[i], collapse=', '), '\\n')\nvcomment        <- m$comment\nnames(vcomment) <- m$name\nmn              <- subset(m, name %in% n)\nlabs            <- mn$label\nun              <- mn$units\nnames(labs)     <- names(un) <- mn$name\nd <- upData(d, labels=labs, units=un)\n```\n:::\n\n\nTo look up the `comment` for a variable at any time use e.g. `vcomment['height']`.  All comments were saved in vector `vcomment` in case the metadata dictionary `m` defined variables that are not in `d` but were to be imported later in the script.  Comments for multiple variables can be looked up using e.g. `vcomment[.q(height, weight, age)]`.\n\n::: {.column-margin}\nIf you want to look up a variable's comment without having to quote its name use the following:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvcom <- function(...)\n  vcomment[as.character(sys.call()[-1])]\n# Example usage: vcom(age,sbp,dbp)\n```\n:::\n\n\n:::\n\n## CSV\n\nThe built-in function in R for reading `.csv` files is [`read.csv`](https://www.rdocumentation.org/packages/utils/versions/3.6.2/topics/read.table).  The `Hmisc` package has a function [`csv.get`](https://www.rdocumentation.org/packages/Hmisc/versions/4.7-0/topics/csv.get) which calls `read.csv` but offers some enhancements in variable naming, date handling, and reading variable labels from a specified row number.  Illegal characters in variable names are changed to periods, and by default underscores are also changed to periods.  If any variable names are changed and the `labels` argument is not given, original variable names are stored in the variable `label` attributes.\n\nThe [`fread`](https://www.rdocumentation.org/packages/data.table/versions/1.14.2/topics/fread) function in the `data.table` package is blazing fast for reading large files and offers a number of options.  `csv.get` uses it if `data.table` is installed on the system.\n\n## REDCap\n\nIf reading data exported from [`REDCap`](https://www.project-redcap.org)  that are placed into the\nproject directory I run the following to get rid of duplicate\n(`factor` and non-`factor` versions of variables `REDCap` produces)\nvariables and automatically convert dates to `Date` variables:\n\n```\nrequire(Hmisc)\ngetRs('importREDCap.r', put='source')  # source() code to define function\nmydata <- importREDCap()  # by default operates on last downloaded export\nsaveRDS(mydata, 'mydata.rds', compress='xz')\n```\n\nWhen file names are not given to `importREDCap` the function looks for\nthe latest created `.csv` file and `.R` file with same prefix and uses those.\nSee [this](http://hbiostat.org/bbr/md/r.html) for more information.\n\n## SAS, Stata, SPSS\n\nSAS, Stata, and SPSS binary files are converted to R `data.frame`s using the R [haven package](https://haven.tidyverse.org).  Here's an example:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrequire(haven)   # after you've installed the package\nd <- read_sas('mydata.sas7bdat')\nd <- read_xpt('mydata.xpt')        # SAS transport files\nd <- read_dta('mydata.dta')        # Stata\nd <- read_sav('mydata.sav')        # SPSS\nd <- read_por('mydata.por')        # Older SPSS files\n```\n:::\n\n\nThese import functions carry variable labels into the data frame and convert dates and times appropriately.  Character vectors are not converted to factors.\n\n## Excel\n\nThe `readxl` package that comes with R reads binary Excel spreadsheet `.xls` and `.xlsx` files to produce something that is almost a data frame.  Here is an example where the imported dataset is converted into a plain `data.frame` and the variable names are changed to all lower case.  `read_excel` does not handle variable labels.  You can specify which sheet or which cell range to import if desired.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd <- readxl::read_excel('my.xlsx')\n# Or use require(readxl) then d <- read_excel(...)\nd <- as.data.frame(d)\n# Or better: make it a data table: setDT(d)\nnames(d) <- tolower(names(d))\n```\n:::\n\n\n\n## Multiple Files\n\nOne of the most important principles to following in programming data analyses is to not do the same thing more than once.  Repetitive code wastes time and is harder to maintain.  One example of avoiding repetition is in reading a large number of files in R.  If the files are stored in one directory and have a consistent file naming scheme (or you want to import every `.csv` file in the directory), one can avoid naming the individual files.  The results may be stored in an R `list` that has named elements, and there are many processing tasks that can be automated by looping over this list.\n\nIn the following example assume that all the data files are `.csv` files in the current working directory, and they all have names of the form `xz*.csv`.  Let's read all of them and put each file into a data frame named by the characters in front of `.csv`.  These data frames are stuffed into a `list` named `X`.  The `Hmisc` `csv.get` function is used to read the files, automatically translating dates to `Date` variables, and because `lowernames=TRUE` is specified, variable names are translated to lower case.  There is an option to fetch variable labels from a certain row of each `.csv` file but we are not using that.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfiles <- list.files(pattern='xz.*.csv')  # vector of qualifying file names\n# Get base part of *.csv\ndnames <- sub('.csv', '', files)\nX <- list()\ni <- 0\nfor(f in files) {\n  cat('Reading file', f, '\\n')\n  i <- i + 1\n  d <- csv.get(f, lowernames=TRUE)\n  # To read SAS, Stata, SPSS binary files use a haven function instead\n  # To convert to data.table do setDT(d) here\n  X[[dnames[i]]] <- d\n}\nsaveRDS(X, 'X.rds', compress='xz')  # Efficiently store all datasets together\n```\n:::\n\n\nTo process one of the datasets one can do things like `summary(X[[3]])` or `summary(X$baseline)` where the third dataset stored was named `baseline` because it was imported from `baseline.csv`.\n\nNow there are many possibilities for processing all the datasets at once such as the following.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nk   <- length(X)          # number of datasets\nnam <- lapply(X, names)   # list with k elements, each is a vector of names\n# Get the union of all variable names used in any dataset\nsort(unique(unlist(nam))) # all the variables appearing in any dataset\n# Get variable names contained in all datasets\ncommon <- names(X[[1]])\nfor(i in 2 : k) {\n  common <- intersect(common, names(X[[i]]))\n  if(! length(common)) break  # intersection already empty\n}\nsort(common)\n# Compute number of variables across datasets\nnvar <- sapply(X, length)  # or ncol\n# Print number of observations per dataset\nsapply(X, nrow)\n# For each variable name count the number of datasets containing it\nw <- data.table(dsname=rep(names(X), nvar), vname=unlist(nam))\nw[, .N, keyby=vname]\n# For each variable create a comma-separated list of datasets\n# containing it\nw[, .(datasets=paste(sort(dsname), collapse=', ')), keyby=vname]\n# For datasets having a subject ID variable named id compute\n# the number of unique ids\nuid <- function(d) if('id' %in% names(d)) length(unique(d$id)) else NA\nsapply(X, uid)\n# To repeatedly analyze one of the datasets, extract it to a single data frame\nd <- X$baseline\ndescribe(d)\n```\n:::\n\n\n## Importing the Latest File\n\nSometimes one keeps multiple versions of the raw data to be imported inside the project folder.  If you want to import the file that was last modified you can use the `reptools` `latestFile` function.  You give it a pattern of file names to match.  For example a pattern of `.csv$` means \"ending with `.csv`\" and a pattern of `^baseline` means \"starting with `baseline`\".  A pattern of `foo` means that `foo` is contained anywhere in the file name.  Here is an example.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Look for file names starting with base, followed by any number of\n# characters, and ending with .csv\nf <- latestFile('^base.*csv$')\nd <- csv.get(f)\n```\n:::\n\n\n## Post Import\n\nThe `Hmisc` package `cleanup.import` function improves imported data storage in a number of ways including converting double precision variables to `integer` when originally `double` but not containing fractional values (this halves the storage requirement).  `Hmisc::upData` is the go-to function for annotating data frames/tables, renaming variables, and dropping variables.  `Hmisc::dataframeReduced` removes problematic variables, e.g., those with a high fraction of missing values or that are binary with very small prevalence.\n\n:::\n\n## Variable Naming\n\nI prefer short but descriptive variable names.  As exemplified above, I use variable `label`s and `units` to provide more information.  For example I wouldn't name the age variable `age.at.enrollment.yrs` but would name it `age` with a label of `Age at Enrollment` and with `units` of `years`.  Short, clear names unclutter code, especially formulas in statistical models.  One can always fetch a variable label while writing a program (e.g., typing `label(d$age)` at the console) to check that you have the right variable (or put the data dictionary in a window for easy reference, as shown below).  `Hmisc` package graphics and table making functions such as `summaryM` and `summary.formula` specially typeset `units` in a smaller font.\n\n\n## Data Dictionary {#sec-fcreate-dd}\n\nThe `Hmisc` package `contents` function will provide a concise data dictionary.    Here is an example using the permanent version (which coded binary variables as 0/1 instead of N/Y) of the dataset created above, which can be accessed with the `Hmisc` `getHdata` function.  The top of the `contents` output has the number of levels for `factor` variables hyperlinked.  Click on the number to go directly to the list of levels for that variable.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrequire(Hmisc)\ngetHdata(stressEcho)\nd <- stressEcho\n```\n:::\n\n\n::: {.callout-note collapse=\"true\"}\n# Data Dictionary\n\n\n\n```{.r .cell-code}\nhtml(contents(d), levelType='table')\n```\n\n::: {.cell-output-display}\n```{=html}\n<title>d Contents</title>\n <hr><h4>Data frame:d</h4>558 observations and 31 variables, maximum # NAs:0&emsp;&emsp;\n <hr>\n <style>\n .hmisctable254782 {\n border: 1px solid gray;\n border-collapse: collapse;\n font-size: 100%;\n }\n .hmisctable254782 td {\n text-align: right;\n padding: 0 1ex 0 1ex;\n }\n .hmisctable254782 th {\n color: Black;\n text-align: center;\n padding: 0 1ex 0 1ex;\n font-weight: bold;\n }\n </style>\n <table class=\"hmisctable254782\" border=\"1\">\n <tr><th>Name</th><th>Labels</th><th>Units</th><th>Levels</th><th>Storage</th></tr>\n <tr><td>bhr</td><td>Basal heart rate</td><td>bpm</td><td></td><td>integer</td></tr>\n <tr><td>basebp</td><td>Basal blood pressure</td><td>mmHg</td><td></td><td>integer</td></tr>\n <tr><td>basedp</td><td>Basal Double Product bhr*basebp</td><td>bpm*mmHg</td><td></td><td>integer</td></tr>\n <tr><td>pkhr</td><td>Peak heart rate</td><td>mmHg</td><td></td><td>integer</td></tr>\n <tr><td>sbp</td><td>Systolic blood pressure</td><td>mmHg</td><td></td><td>integer</td></tr>\n <tr><td>dp</td><td>Double product pkhr*sbp</td><td>bpm*mmHg</td><td></td><td>integer</td></tr>\n <tr><td>dose</td><td>Dose of dobutamine given</td><td>mg</td><td></td><td>integer</td></tr>\n <tr><td>maxhr</td><td>Maximum heart rate</td><td>bpm</td><td></td><td>integer</td></tr>\n <tr><td>pctMphr</td><td>Percent maximum predicted heart rate achieved</td><td>%</td><td></td><td>integer</td></tr>\n <tr><td>mbp</td><td>Maximum blood pressure</td><td>mmHg</td><td></td><td>integer</td></tr>\n <tr><td>dpmaxdo</td><td>Double product on max dobutamine dose</td><td>bpm*mmHg</td><td></td><td>integer</td></tr>\n <tr><td>dobdose</td><td>Dobutamine dose at max double product</td><td>mg</td><td></td><td>integer</td></tr>\n <tr><td>age</td><td>Age</td><td>years</td><td></td><td>integer</td></tr>\n <tr><td>gender</td><td></td><td></td><td><a href=\"#levels.gender\">2</a></td><td>integer</td></tr>\n <tr><td>baseEF</td><td>Baseline cardiac ejection fraction</td><td>%</td><td></td><td>integer</td></tr>\n <tr><td>dobEF</td><td>Ejection fraction on dobutamine</td><td>%</td><td></td><td>integer</td></tr>\n <tr><td>chestpain</td><td>Chest pain</td><td></td><td></td><td>integer</td></tr>\n <tr><td>restwma</td><td>Resting wall motion abnormality on echocardiogram</td><td></td><td></td><td>integer</td></tr>\n <tr><td>posSE</td><td>Positive stress echocardiogram</td><td></td><td></td><td>integer</td></tr>\n <tr><td>newMI</td><td>New myocardial infarction</td><td></td><td></td><td>integer</td></tr>\n <tr><td>newPTCA</td><td>Recent angioplasty</td><td></td><td></td><td>integer</td></tr>\n <tr><td>newCABG</td><td>Recent bypass surgery</td><td></td><td></td><td>integer</td></tr>\n <tr><td>death</td><td></td><td></td><td></td><td>integer</td></tr>\n <tr><td>hxofHT</td><td>History of hypertension</td><td></td><td></td><td>integer</td></tr>\n <tr><td>hxofDM</td><td>History of diabetes</td><td></td><td></td><td>integer</td></tr>\n <tr><td>hxofCig</td><td>History of smoking</td><td></td><td><a href=\"#levels.hxofCig\">3</a></td><td>integer</td></tr>\n <tr><td>hxofMI</td><td>History of myocardial infarction</td><td></td><td></td><td>integer</td></tr>\n <tr><td>hxofPTCA</td><td>History of angioplasty</td><td></td><td></td><td>integer</td></tr>\n <tr><td>hxofCABG</td><td>History of coronary artery bypass surgery</td><td></td><td></td><td>integer</td></tr>\n <tr><td>any.event</td><td>Death, newMI, newPTCA, or newCABG</td><td></td><td></td><td>integer</td></tr>\n <tr><td>ecg</td><td>Baseline electrocardiogram diagnosis</td><td></td><td><a href=\"#levels.ecg\">3</a></td><td>integer</td></tr>\n </table>\n\n <hr>\n <style>\n .hmisctable838155 {\n border: 1px solid gray;\n border-collapse: collapse;\n font-size: 100%;\n }\n .hmisctable838155 td {\n text-align: right;\n padding: 0 1ex 0 1ex;\n }\n .hmisctable838155 th {\n color: Black;\n text-align: center;\n padding: 0 1ex 0 1ex;\n font-weight: bold;\n }\n </style>\n <table class=\"hmisctable838155\" border=\"1\">\n <tr><th>Variable</th><th>Levels</th></tr>\n <tr><td><a name=\"levels.gender\">gender</a></td><td>male</td></tr>\n <tr><td></td><td>female</td></tr>\n <tr><td><a name=\"levels.ecg\">hxofCig</a></td><td>heavy</td></tr>\n <tr><td></td><td>moderate</td></tr>\n <tr><td></td><td>non-smoker</td></tr>\n <tr><td><a name=\"levels.ecg\">ecg</a></td><td>normal</td></tr>\n <tr><td></td><td>equivocal</td></tr>\n <tr><td></td><td>MI</td></tr>\n </table>\n\n <hr>\n\n```\n:::\n\n:::\n\nYou can write the text output of `contents` into a text file in your current working directory, and click on that file in the `RStudio` `Files` window to create a new tab in the editor panel where you can view the data dictionary at any time.  This is especially helpful if you need a reminder of variable definitions that are stored in the variable labels.  Here is an example where the formatted data dictionary is saved.  [Users having the `xless` system command installed can pop up a `contents` window at any time by typing `xless(contents(d))` in the console. `xless` is in `Hmisc`.]{.aside}\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncapture.output(contents(d), file='contents.txt')\n```\n:::\n\n\nOr put the html version of the data dictionary into a small browser window to which you can refer at any point in analysis coding.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncat(html(contents(d)), file='contents.html')\nbrowseURL('contents.html', browser='vivaldi -new-window')\n```\n:::\n\n\n\n`RStudio` provides a nice way to do this, facilitated by the `htmlView` helper function in `reptools`.  `htmlView` takes any number of objects for which an `html` method exists to render them.  They are rendered in the `RStudio` `Viewer` pane.  If you are running outside `RStudio`, your default browser will be launched instead.[Occasionally `RStudio Viewer` will drop its arrow button making it impossible to navigate back and forth to different `html` outputs.<br>Code for `htmlView` and `htmlViewx` may be viewed in [`reptools.r`](https://github.com/harrelfe/rscripts/blob/master/reptools.r).]{.aside}\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngetRs('reptools.r', put='source')\n# reptools.r defines htmlView, htmlViewx, kabl, maketabs, dataChk, ...\nhtmlView(contents(d))\n```\n:::\n\n\nIn some cases it is best to have a browser window open to the full descriptive statistics for a data table/frame (see below; the `describe` function also shows labels, units, and levels).  [For either approach it would be easy to have multiple tabs open, one tab for each of a series of data tables, or use `htmlView`.]{.aside}\n\nTo be able to have multiple windows open to see information about datasets it is advantageous to open an external browser window.  The `htmlViewx` function will by default open a Vivaldi browser window with the first output put in a new window and all subsequent objects displayed as tabs within that same window.  This behavior can be controlled with the `tab` argument, and you can use a different browser by issuing for example `options(vbrowser='firefox')`.[In Windows you may have to specify a full path and `firefox.exe`.  The tab names will not be correct until `Hmisc` 4.7-1 appears.]{.aside}  As an example suppose that two datasets were read from the `hbiostat.org/data` data repository, and the data dictionary and descriptive statistics for both datasets were to be converted to `html` and placed in an external browser window for the duration of the R session.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngetHdata(support)\ngetHdata(support2)\nhtmlViewx(contents(support ), describe(support ),\n          contents(support2), describe(support2))\n```\n:::\n\n\nA screenshot of the result is [here](https://hbiostat.org/img/htmlViewx.png).",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}